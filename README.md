# Adaptive Edge AI ğŸ¤–

![Edge AI Banner](https://github.com/msadeqsirjani/adaptive_edge_ai/blob/master/docs/images/banner.png)

## ğŸ“‹ Overview

Adaptive Edge AI is a project focused on optimizing and deploying deep learning models for edge devices through model compression and knowledge distillation techniques. This solution enables efficient AI model deployment on resource-constrained devices while maintaining high performance.

## ğŸŒŸ Key Features

- ğŸ”„ Model Compression
- ğŸ“š Knowledge Distillation
- ğŸ“± Edge Device Optimization
- ğŸ“Š Adaptive Performance Scaling
- ğŸš€ ONNX Export Support

## ğŸ—ï¸ Architecture

```mermaid
graph LR
A[Teacher Model] --> B[Knowledge Distillation]
B --> C[Student Model]
C --> D[Model Compression]
D --> E[Edge Deployment]
```


## ğŸ› ï¸ Installation

1. Clone the repository

```bash
git clone https://github.com/msadeqsirjani/adaptive_edge_ai.git
```

2. Create and activate virtual environment

```bash
python -m venv .venv
source .venv/bin/activate # Linux/Mac
# or
.venv\Scripts\activate # Windows
```

3. Install dependencies

```bash
pip install -r requirements.txt
```


## ğŸ“Š Performance Metrics

| Model | Size | Accuracy | Inference Time |
|-------|------|----------|----------------|
| Teacher | 500MB | 95% | 100ms |
| Student | 50MB | 92% | 20ms |
| Compressed | 10MB | 90% | 5ms |

## ğŸ’» Usage

### Training the Teacher Model

```bash
python main.py --mode train_teacher --data_path data/
```

### Knowledge Distillation

```bash
python main.py --mode distill --teacher_model best_teacher_model.pth
```

### Model Compression

```bash
python main.py --mode compress --model student_model.pth
```


## ğŸ“ Project Structure

```bash
adaptive_edge_ai/
â”œâ”€â”€ data/ # Dataset directory (gitignored)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ models/ # Model architectures
â”‚ â”œâ”€â”€ optimization/ # Compression algorithms
â”‚ â”œâ”€â”€ training/ # Training utilities
â”‚ â””â”€â”€ utils/ # Helper functions
â”œâ”€â”€ outputs/ # Saved models & results
â”œâ”€â”€ tests/ # Unit tests
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ main.py # Entry point
```


## ğŸ“ˆ Results

Our compressed models achieve:
- ğŸ“‰ 90% size reduction
- âš¡ 20x faster inference
- ğŸ’ª Minimal accuracy loss

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“¬ Contact

- `Mohammad Sadegh Sirjani` - [@msadeqsirjani](https://twitter.com/msadeqsirjani)
- Email - `m.sadeq.sirjani@gmail.com`

## ğŸ™ Acknowledgments

- Thanks to relevant papers or projects
- Special thanks to contributors
- Inspired by related work

---
â­ Don't forget to star this repo if you find it helpful!